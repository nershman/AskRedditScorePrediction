{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary packages and setting for multiprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, unidecode, re, os, json\n",
    "import matplotlib as plt\n",
    "import networkx as nx\n",
    "from networkx.algorithms.traversal.depth_first_search import dfs_tree\n",
    "from dask.distributed import Client\n",
    "import dask.dataframe as dd\n",
    "from nltk.corpus import stopwords\n",
    "from multiprocessing import dummy\n",
    "\n",
    "core = os.cpu_count() - 2\n",
    "client = Client(n_workers = core, threads_per_worker = 1, memory_limit = '25GB')\n",
    "my_stopwords = stopwords.words('english')\n",
    "P = dummy.Pool(processes = core)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:\\\\M2 EconStat\\\\Web Mining\\\\Project\\\\comments_students.csv'\n",
    "df = pd.read_csv(path, header = 0, engine = 'c',\n",
    "                 usecols = ['created_utc', 'ups', 'link_id', 'id', 'author', 'body', 'parent_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove prefix so that columns `parent_id` and `link_id` have the same format as column `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parent_id'] = df['parent_id'].str.split('_', expand = True)[1]\n",
    "df['link_id'] = df['link_id'].str.split('_', expand = True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ind` is the indices of  \"normal\" rows that will be fed into the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = (df['body'] != 'deleted') & (df['body'] != '[deleted]') & df['body'].notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save this dataset for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'E:\\\\M2 EconStat\\\\Web Mining\\\\prefix_removed.csv'\n",
    "df.to_csv(path, index = False, encoding =  'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the root for every tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'E:\\\\M2 EconStat\\\\Web Mining\\\\prefix_removed.csv'\n",
    "df = pd.read_csv(path, header = 0, engine = 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is that a comment is a root if it does not reply any comment in the dataset. Hence its `in_degree` is $0$. Of course, a comment with `link_id` = `parent_id` is a root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(df, source = 'parent_id', target = 'id', create_using = nx.DiGraph())\n",
    "roots = [n for n, d in G.in_degree() if d == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `para_func` below takes a root as input and returns a dataframe. Column `id` contains all the nodes of the tree characterized by the root. We extract this tree by `dfs_tree`. All elements in column `root` are the same, i.e the root itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_func(r):\n",
    "    node = list(dfs_tree(G, r).nodes)\n",
    "    tree = G.subgraph(node)\n",
    "    node.remove(r)\n",
    "    root =  pd.DataFrame({'id': node, 'root': [r] * len(node)})\n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation is not computationally intensive, so I use `multiprocessing.dummy.Pool` for simple implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_node_list = P.map(para_func, roots)\n",
    "root_node = pd.concat(root_node_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add this root-node information to original dataframe. Notice that the original dataframe does not contain comments that are roots. That's why we specify `how = 'left'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(root_node, how = 'left', on = 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save this dataset for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'E:\\\\M2 EconStat\\\\Web Mining\\\\root_included.csv'\n",
    "df.to_csv(path, index = False, encoding =  'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract graph-related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'E:\\\\M2 EconStat\\\\Web Mining\\\\root_included.csv'\n",
    "df = dd.read_csv(path, header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create column `timestamp` to compute time interval later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = dd.to_datetime(df['created_utc'], utc = True, unit = 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the list of features we will extract.\n",
    "\n",
    "- *Timing*: time since root, time since parent (in hours), number of later comments, and number of previous comments\n",
    "\n",
    "- *Author*: a binary indicator as to whether the author is the original poster, and number of comments made by the author in the conversation\n",
    "\n",
    "- *Graph-location*: depth of the comment (distance from the root), and number of siblings\n",
    "\n",
    "- *Graph-response*: number of children (direct replies to the comment), height of the subtree rooted from the node, size of that subtree, number of children normalized for each thread (2 normalization techniques), subtree size normalized for each thread (2 normalization techniques).\n",
    "\n",
    "I could not find any package containing functions to compute all features, except for *depth of the comment*, *height of the subtree*, and *size of that subtree*. Luckily, our subgraphs are of a special kind, [arborescence](https://www.wikiwand.com/en/Tree_(graph_theory)#/Rooted_tree). This allows us to utilize package `dask` and highly optimized functions from package `pandas` to speed up computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we compute features related to the subgraph characterized by column `root`. Comments with the same `root` are in the same subgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extract(sub_df):\n",
    "    r = sub_df['root'].iloc[0]\n",
    "    tree = nx.from_pandas_edgelist(sub_df,\n",
    "                                   source = 'parent_id',\n",
    "                                   target = 'id',\n",
    "                                   create_using = nx.DiGraph())\n",
    "\n",
    "    count_utc = sub_df.groupby('created_utc').size()\n",
    "    cum_previous_counts = count_utc.sort_index(ascending = True).shift(fill_value = 0).cumsum()\n",
    "    cum_later_counts = count_utc.sort_index(ascending = False).shift(fill_value = 0).cumsum()\n",
    "    time_parent = sub_df.parent_id.map(dict(zip(sub_df.id, sub_df.timestamp)))\n",
    "\n",
    "    depth = [nx.shortest_path_length(tree, source = r, target = n) for n in sub_df.id]\n",
    "    num_siblings = sub_df.groupby('parent_id').parent_id.transform('count')\n",
    "    num_children = sub_df.groupby('parent_id').size().reindex(sub_df.id, fill_value = 0)\n",
    "    num_comments_author = sub_df.groupby('author').author.transform('count')\n",
    "    num_previous_comments = sub_df.created_utc.map(cum_previous_counts)\n",
    "    num_later_comments = sub_df.created_utc.map(cum_later_counts)\n",
    "    time_since_root = (sub_df.timestamp - sub_df.timestamp.min()) / pd.Timedelta(hours = 1)\n",
    "    time_since_parent = ((sub_df.timestamp - time_parent) / pd.Timedelta(hours = 1)).fillna(0)\n",
    "\n",
    "    data = list(zip(sub_df.id, depth, num_siblings, num_children, num_comments_author,\n",
    "                    num_previous_comments, num_later_comments, time_since_root, time_since_parent))\n",
    "\n",
    "    columns = ['id', 'depth', 'num_siblings', 'num_children', 'num_comments_author',\n",
    "              'num_previous_comments', 'num_later_comments', 'time_since_root', 'time_since_parent']\n",
    "\n",
    "    return pd.DataFrame(data, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>depth</th>\n",
       "      <th>num_siblings</th>\n",
       "      <th>num_children</th>\n",
       "      <th>num_comments_author</th>\n",
       "      <th>num_previous_comments</th>\n",
       "      <th>num_later_comments</th>\n",
       "      <th>time_since_root</th>\n",
       "      <th>time_since_parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cr1qq1w</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cqvdyoy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cqxivp8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cqxiruo</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cqws27u</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234965</th>\n",
       "      <td>cquiajn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234966</th>\n",
       "      <td>cqumskx</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.025556</td>\n",
       "      <td>2.025556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234967</th>\n",
       "      <td>cquxm86</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11.754444</td>\n",
       "      <td>9.728889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234968</th>\n",
       "      <td>cqugv6d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234969</th>\n",
       "      <td>crjrvf6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4234970 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  depth  num_siblings  num_children  num_comments_author  \\\n",
       "0        cr1qq1w      1             1             0                    1   \n",
       "1        cqvdyoy      1             1             0                    1   \n",
       "2        cqxivp8      1             1             0                    1   \n",
       "3        cqxiruo      1             1             0                    1   \n",
       "4        cqws27u      1             1             0                    1   \n",
       "...          ...    ...           ...           ...                  ...   \n",
       "4234965  cquiajn      1             1             1                    1   \n",
       "4234966  cqumskx      2             1             1                    1   \n",
       "4234967  cquxm86      3             1             0                    1   \n",
       "4234968  cqugv6d      1             1             0                    1   \n",
       "4234969  crjrvf6      1             1             0                    1   \n",
       "\n",
       "         num_previous_comments  num_later_comments  time_since_root  \\\n",
       "0                            0                   0         0.000000   \n",
       "1                            0                   0         0.000000   \n",
       "2                            0                   0         0.000000   \n",
       "3                            0                   0         0.000000   \n",
       "4                            0                   0         0.000000   \n",
       "...                        ...                 ...              ...   \n",
       "4234965                      0                   2         0.000000   \n",
       "4234966                      1                   1         2.025556   \n",
       "4234967                      2                   0        11.754444   \n",
       "4234968                      0                   0         0.000000   \n",
       "4234969                      0                   0         0.000000   \n",
       "\n",
       "         time_since_parent  \n",
       "0                 0.000000  \n",
       "1                 0.000000  \n",
       "2                 0.000000  \n",
       "3                 0.000000  \n",
       "4                 0.000000  \n",
       "...                    ...  \n",
       "4234965           0.000000  \n",
       "4234966           2.025556  \n",
       "4234967           9.728889  \n",
       "4234968           0.000000  \n",
       "4234969           0.000000  \n",
       "\n",
       "[4234970 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = {'id': object, 'depth': np.int64, 'num_siblings': np.int64, 'num_children': np.int64,\n",
    "       'num_comments_author': np.int64, 'num_previous_comments': np.int64, 'num_later_comments': np.int64,\n",
    "       'time_since_root': np.float64, 'time_since_parent': np.float64}\n",
    "\n",
    "result = df.groupby('root').apply(features_extract, meta = meta)\n",
    "result = result.compute(scheduler = 'processes')\n",
    "result.reset_index(inplace = True, drop = True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remark 1:*\n",
    "\n",
    "- I use `.compute()` or equivalently `.compute(scheduler = 'threads')`. The executing time is reduced to $30$ minutes. The utilization of CPU increases from $25\\%$ to $50\\%$. Previously, I used `multiprocessing.dummy.Pool()` and my laptop could not finish the computation in 3 hours. I had no choice but to interupt Python kernel.\n",
    "\n",
    "- Then I come across this [answer](https://stackoverflow.com/a/31364127/7357673) and change to `.compute(scheduler = 'processes')`. The utilization of CPU is almost $100\\%$. The executing time is reduced to just $12$ minutes. This is awesome.\n",
    "\n",
    "*Remark 2:*\n",
    "\n",
    "- At first I thought `dask` only works with function that returns a dictionary. This means I have to do $2$ more steps, i.e. converting resulted dictionaries to pandas dataframe and then concatenating them together. Even I used `multiprocessing.dummy.Pool()`, the conversion still took up to $2.5$ minutes.\n",
    "\n",
    "- Then I come across this [documentation](https://docs.dask.org/en/latest/dataframe-design.html#metadata). It tells that `dask` works perfectly with function that returns a pandas dataframe (It should ^_^). We only need to specify the correct data types with option `meta`. One advantage of this approach is that `dask` automatically concatenate resulted dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of comments and height of the subtree rooted from the comment itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first create a graph from the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(df,\n",
    "                            source = 'parent_id',\n",
    "                            target = 'id',\n",
    "                            create_using = nx.DiGraph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, `multiprocessing.dummy.Pool` and `dask.Series.apply` take almost the same amount of time to finish. This makes sense because `features_extract` is applied on **every** comment in the dataset. Hence `dask.Series.apply` does not have any advantage by cleverly partitioning the dataframe.\n",
    "\n",
    "Last but not least, `dask.Series.apply` has a disadvantage, i.e. it can not be called on an existing Dask dataframe. To use it, we need to import our dataset again with `pd.read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_comments_subtree</th>\n",
       "      <th>height_subtree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cqug90j</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cqug90k</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cqug90z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cqug91c</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cqug91e</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234965</th>\n",
       "      <td>crrbelu</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234966</th>\n",
       "      <td>crrbelv</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234967</th>\n",
       "      <td>crrbemp</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234968</th>\n",
       "      <td>crrbenh</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234969</th>\n",
       "      <td>crrbeop</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4234970 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  num_comments_subtree  height_subtree\n",
       "0        cqug90j                     1               0\n",
       "1        cqug90k                     1               0\n",
       "2        cqug90z                     1               0\n",
       "3        cqug91c                     1               0\n",
       "4        cqug91e                     3               2\n",
       "...          ...                   ...             ...\n",
       "4234965  crrbelu                     1               0\n",
       "4234966  crrbelv                     1               0\n",
       "4234967  crrbemp                     1               0\n",
       "4234968  crrbenh                     1               0\n",
       "4234969  crrbeop                     1               0\n",
       "\n",
       "[4234970 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def features_extract(r):\n",
    "    subtree = dfs_tree(G, r)\n",
    "    num_comment = subtree.number_of_nodes()\n",
    "    height_subtree = nx.dag_longest_path_length(subtree)\n",
    "    return [r, num_comment, height_subtree]\n",
    "\n",
    "result2 = P.map(features_extract, df.id)\n",
    "result2 = pd.DataFrame(result2, columns = ['id', 'num_comments_subtree', 'height_subtree'])\n",
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add these features to our original daraframe. By construction, `df`, `compute_result`, and `sub_tree_infor` have exactly the same elements in column `id`. That's why dont need to specify parameter `how`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>ups</th>\n",
       "      <th>link_id</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>root</th>\n",
       "      <th>depth</th>\n",
       "      <th>num_siblings</th>\n",
       "      <th>num_children</th>\n",
       "      <th>num_comments_author</th>\n",
       "      <th>num_previous_comments</th>\n",
       "      <th>num_later_comments</th>\n",
       "      <th>time_since_root</th>\n",
       "      <th>time_since_parent</th>\n",
       "      <th>num_comments_subtree</th>\n",
       "      <th>height_subtree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430438400</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34f9rh</td>\n",
       "      <td>cqug90j</td>\n",
       "      <td>jesse9o3</td>\n",
       "      <td>No one has a European accent either  because i...</td>\n",
       "      <td>cqug2sr</td>\n",
       "      <td>cqug2sr</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1430438400</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34fvry</td>\n",
       "      <td>cqug90k</td>\n",
       "      <td>beltfedshooter</td>\n",
       "      <td>That the kid ..reminds me of Kevin.   so sad :-(</td>\n",
       "      <td>34fvry</td>\n",
       "      <td>34fvry</td>\n",
       "      <td>1</td>\n",
       "      <td>1443</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1430438400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34ffo5</td>\n",
       "      <td>cqug90z</td>\n",
       "      <td>InterimFatGuy</td>\n",
       "      <td>NSFL</td>\n",
       "      <td>cqu80zb</td>\n",
       "      <td>cqu80zb</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1430438401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34aqsn</td>\n",
       "      <td>cqug91c</td>\n",
       "      <td>JuanTutrego</td>\n",
       "      <td>I'm a guy and I had no idea this was a thing g...</td>\n",
       "      <td>cqtdj4m</td>\n",
       "      <td>cqtdj4m</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1430438401</td>\n",
       "      <td>101.0</td>\n",
       "      <td>34f9rh</td>\n",
       "      <td>cqug91e</td>\n",
       "      <td>dcblackbelt</td>\n",
       "      <td>Mid twenties male rocking skinny jeans/pants, ...</td>\n",
       "      <td>cquc4rc</td>\n",
       "      <td>cquc4rc</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234965</th>\n",
       "      <td>1433116795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37y5rx</td>\n",
       "      <td>crrbelu</td>\n",
       "      <td>monster860</td>\n",
       "      <td>Does the sun set in the west/rise in the east?...</td>\n",
       "      <td>37y5rx</td>\n",
       "      <td>37y5rx</td>\n",
       "      <td>1</td>\n",
       "      <td>1496</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3265</td>\n",
       "      <td>0</td>\n",
       "      <td>12.452222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234966</th>\n",
       "      <td>1433116795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37y5rx</td>\n",
       "      <td>crrbelv</td>\n",
       "      <td>jsimo36</td>\n",
       "      <td>Coffee.</td>\n",
       "      <td>37y5rx</td>\n",
       "      <td>37y5rx</td>\n",
       "      <td>1</td>\n",
       "      <td>1496</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3265</td>\n",
       "      <td>0</td>\n",
       "      <td>12.452222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234967</th>\n",
       "      <td>1433116796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>380jx2</td>\n",
       "      <td>crrbemp</td>\n",
       "      <td>torianicole731</td>\n",
       "      <td>people who cannot make up their mind, my bulls...</td>\n",
       "      <td>380jx2</td>\n",
       "      <td>380jx2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234968</th>\n",
       "      <td>1433116797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37yawp</td>\n",
       "      <td>crrbenh</td>\n",
       "      <td>bellypouch</td>\n",
       "      <td>Give them to Irish people in exchange for doin...</td>\n",
       "      <td>37yawp</td>\n",
       "      <td>37yawp</td>\n",
       "      <td>1</td>\n",
       "      <td>1779</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3519</td>\n",
       "      <td>0</td>\n",
       "      <td>11.398056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234969</th>\n",
       "      <td>1433116799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37zhvy</td>\n",
       "      <td>crrbeop</td>\n",
       "      <td>NotByAnyMeans</td>\n",
       "      <td>classy way to put it</td>\n",
       "      <td>crragip</td>\n",
       "      <td>37zhvy</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>5.230000</td>\n",
       "      <td>0.501944</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4234970 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         created_utc    ups link_id       id          author  \\\n",
       "0         1430438400    3.0  34f9rh  cqug90j        jesse9o3   \n",
       "1         1430438400    3.0  34fvry  cqug90k  beltfedshooter   \n",
       "2         1430438400    5.0  34ffo5  cqug90z   InterimFatGuy   \n",
       "3         1430438401    1.0  34aqsn  cqug91c     JuanTutrego   \n",
       "4         1430438401  101.0  34f9rh  cqug91e     dcblackbelt   \n",
       "...              ...    ...     ...      ...             ...   \n",
       "4234965   1433116795    NaN  37y5rx  crrbelu      monster860   \n",
       "4234966   1433116795    NaN  37y5rx  crrbelv         jsimo36   \n",
       "4234967   1433116796    NaN  380jx2  crrbemp  torianicole731   \n",
       "4234968   1433116797    NaN  37yawp  crrbenh      bellypouch   \n",
       "4234969   1433116799    NaN  37zhvy  crrbeop   NotByAnyMeans   \n",
       "\n",
       "                                                      body parent_id     root  \\\n",
       "0        No one has a European accent either  because i...   cqug2sr  cqug2sr   \n",
       "1         That the kid ..reminds me of Kevin.   so sad :-(    34fvry   34fvry   \n",
       "2                                                     NSFL   cqu80zb  cqu80zb   \n",
       "3        I'm a guy and I had no idea this was a thing g...   cqtdj4m  cqtdj4m   \n",
       "4        Mid twenties male rocking skinny jeans/pants, ...   cquc4rc  cquc4rc   \n",
       "...                                                    ...       ...      ...   \n",
       "4234965  Does the sun set in the west/rise in the east?...    37y5rx   37y5rx   \n",
       "4234966                                           Coffee.     37y5rx   37y5rx   \n",
       "4234967  people who cannot make up their mind, my bulls...    380jx2   380jx2   \n",
       "4234968  Give them to Irish people in exchange for doin...    37yawp   37yawp   \n",
       "4234969                               classy way to put it   crragip   37zhvy   \n",
       "\n",
       "         depth  num_siblings  num_children  num_comments_author  \\\n",
       "0            1             1             0                    1   \n",
       "1            1          1443             0                    1   \n",
       "2            1             5             0                    1   \n",
       "3            1             4             0                    1   \n",
       "4            1             2             1                    1   \n",
       "...        ...           ...           ...                  ...   \n",
       "4234965      1          1496             0                    1   \n",
       "4234966      1          1496             0                    1   \n",
       "4234967      1             9             0                    1   \n",
       "4234968      1          1779             0                    1   \n",
       "4234969      7             1             0                    1   \n",
       "\n",
       "         num_previous_comments  num_later_comments  time_since_root  \\\n",
       "0                            0                   0         0.000000   \n",
       "1                            0                3512         0.000000   \n",
       "2                            0                  11         0.000000   \n",
       "3                            0                   4         0.000000   \n",
       "4                            0                   3         0.000000   \n",
       "...                        ...                 ...              ...   \n",
       "4234965                   3265                   0        12.452222   \n",
       "4234966                   3265                   0        12.452222   \n",
       "4234967                      8                   0         0.522500   \n",
       "4234968                   3519                   0        11.398056   \n",
       "4234969                    258                   0         5.230000   \n",
       "\n",
       "         time_since_parent  num_comments_subtree  height_subtree  \n",
       "0                 0.000000                     1               0  \n",
       "1                 0.000000                     1               0  \n",
       "2                 0.000000                     1               0  \n",
       "3                 0.000000                     1               0  \n",
       "4                 0.000000                     3               2  \n",
       "...                    ...                   ...             ...  \n",
       "4234965           0.000000                     1               0  \n",
       "4234966           0.000000                     1               0  \n",
       "4234967           0.000000                     1               0  \n",
       "4234968           0.000000                     1               0  \n",
       "4234969           0.501944                     1               0  \n",
       "\n",
       "[4234970 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'E:\\\\M2 EconStat\\\\Web Mining\\\\root_included.csv'\n",
    "df = pd.read_csv(path, header = 0, engine = 'c')\n",
    "df = df.merge(result, on = 'id')\n",
    "df = df.merge(result2, on = 'id')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save it for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'E:\\\\M2 EconStat\\\\Web Mining\\\\features_included.csv'\n",
    "df.to_csv(path, index = False, encoding =  'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(df, colname, ind):\n",
    "    \n",
    "    tmp = df[colname][ind].copy()\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    tmp = tmp.str.lower()\n",
    "    \n",
    "    # Delete punctuation\n",
    "    tmp = tmp.str.replace('\\n', ' ')\n",
    "    tmp = tmp.str.replace('\\r', ' ')    \n",
    "    tmp = tmp.str.replace(r\"((?!{}).)\".format('(\\\\b[-/]\\\\b|[a-zA-Z0-9])'), ' ', regex = True)\n",
    "    \n",
    "    # Tokenize\n",
    "    tmp = tmp.str.split()\n",
    "    \n",
    "    # Delete stop words\n",
    "    tmp = tmp.apply(lambda x: [w for w in x if w not in my_stopwords])\n",
    "    \n",
    "    # Reverse tokenize\n",
    "    df.loc[ind, colname] = tmp.map(lambda word: ' '.join(word))\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = text_cleaning(df, 'body', ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['body']\n",
    "y = df['ups']\n",
    "\n",
    "n_feature = 50\n",
    "\n",
    "tfi_df_vec = TfidfVectorizer(use_idf = True,\n",
    "                             max_features = n_feature)\n",
    "\n",
    "X = tfi_df_vec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.33,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_jobs = -1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get the mean absolute error on the validation data\n",
    "y_pred = model.predict(X_test)\n",
    "MAE = mean_absolute_error(y_test , y_pred)\n",
    "print('Random forest validation MAE = ', MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBRegressor\n",
    "# XGBModel = XGBRegressor()\n",
    "# XGBModel.fit(X_train, y_train , verbose = False)\n",
    "\n",
    "# # Get the mean absolute error on the validation data :\n",
    "# XGBpredictions = XGBModel.predict(X_test)\n",
    "# MAE = mean_absolute_error(y_test , XGBpredictions)\n",
    "# print('XGBoost validation MAE = ', MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(1000, input_dim = 1000, activation = 'relu', kernel_initializer='normal'))\n",
    "# model.add(Dense(8, activation = 'relu', kernel_initializer='normal'))\n",
    "# model.add(Dense(1, activation = 'linear', kernel_initializer='normal'))\n",
    "# model.compile(loss = 'mean_absolute_error',\n",
    "#               optimizer = 'adam',\n",
    "#               metrics = ['accuracy'])\n",
    "# print(model.summary())\n",
    "# model.fit(X_train, y_train,\n",
    "#           epochs = 3,\n",
    "#           batch_size = 10,\n",
    "#           validation_data = (X_test, y_test),\n",
    "#           verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
