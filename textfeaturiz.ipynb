{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>ups</th>\n",
       "      <th>link_id</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>root</th>\n",
       "      <th>depth</th>\n",
       "      <th>num_siblings</th>\n",
       "      <th>num_children</th>\n",
       "      <th>num_comments_author</th>\n",
       "      <th>num_previous_comments</th>\n",
       "      <th>num_later_comments</th>\n",
       "      <th>time_since_root</th>\n",
       "      <th>time_since_parent</th>\n",
       "      <th>num_comments_subtree</th>\n",
       "      <th>height_subtree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430438400</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34f9rh</td>\n",
       "      <td>cqug90j</td>\n",
       "      <td>jesse9o3</td>\n",
       "      <td>No one has a European accent either  because i...</td>\n",
       "      <td>cqug2sr</td>\n",
       "      <td>cqug2sr</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1430438400</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34fvry</td>\n",
       "      <td>cqug90k</td>\n",
       "      <td>beltfedshooter</td>\n",
       "      <td>That the kid ..reminds me of Kevin.   so sad :-(</td>\n",
       "      <td>34fvry</td>\n",
       "      <td>34fvry</td>\n",
       "      <td>1</td>\n",
       "      <td>1443</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1430438400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34ffo5</td>\n",
       "      <td>cqug90z</td>\n",
       "      <td>InterimFatGuy</td>\n",
       "      <td>NSFL</td>\n",
       "      <td>cqu80zb</td>\n",
       "      <td>cqu80zb</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1430438401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34aqsn</td>\n",
       "      <td>cqug91c</td>\n",
       "      <td>JuanTutrego</td>\n",
       "      <td>I'm a guy and I had no idea this was a thing g...</td>\n",
       "      <td>cqtdj4m</td>\n",
       "      <td>cqtdj4m</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1430438401</td>\n",
       "      <td>101.0</td>\n",
       "      <td>34f9rh</td>\n",
       "      <td>cqug91e</td>\n",
       "      <td>dcblackbelt</td>\n",
       "      <td>Mid twenties male rocking skinny jeans/pants, ...</td>\n",
       "      <td>cquc4rc</td>\n",
       "      <td>cquc4rc</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234965</th>\n",
       "      <td>1433116795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37y5rx</td>\n",
       "      <td>crrbelu</td>\n",
       "      <td>monster860</td>\n",
       "      <td>Does the sun set in the west/rise in the east?...</td>\n",
       "      <td>37y5rx</td>\n",
       "      <td>37y5rx</td>\n",
       "      <td>1</td>\n",
       "      <td>1496</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3265</td>\n",
       "      <td>0</td>\n",
       "      <td>12.452222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234966</th>\n",
       "      <td>1433116795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37y5rx</td>\n",
       "      <td>crrbelv</td>\n",
       "      <td>jsimo36</td>\n",
       "      <td>Coffee.</td>\n",
       "      <td>37y5rx</td>\n",
       "      <td>37y5rx</td>\n",
       "      <td>1</td>\n",
       "      <td>1496</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3265</td>\n",
       "      <td>0</td>\n",
       "      <td>12.452222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234967</th>\n",
       "      <td>1433116796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>380jx2</td>\n",
       "      <td>crrbemp</td>\n",
       "      <td>torianicole731</td>\n",
       "      <td>people who cannot make up their mind, my bulls...</td>\n",
       "      <td>380jx2</td>\n",
       "      <td>380jx2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234968</th>\n",
       "      <td>1433116797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37yawp</td>\n",
       "      <td>crrbenh</td>\n",
       "      <td>bellypouch</td>\n",
       "      <td>Give them to Irish people in exchange for doin...</td>\n",
       "      <td>37yawp</td>\n",
       "      <td>37yawp</td>\n",
       "      <td>1</td>\n",
       "      <td>1779</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3519</td>\n",
       "      <td>0</td>\n",
       "      <td>11.398056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234969</th>\n",
       "      <td>1433116799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37zhvy</td>\n",
       "      <td>crrbeop</td>\n",
       "      <td>NotByAnyMeans</td>\n",
       "      <td>classy way to put it</td>\n",
       "      <td>crragip</td>\n",
       "      <td>37zhvy</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>5.230000</td>\n",
       "      <td>0.501944</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4234970 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         created_utc    ups link_id       id          author  \\\n",
       "0         1430438400    3.0  34f9rh  cqug90j        jesse9o3   \n",
       "1         1430438400    3.0  34fvry  cqug90k  beltfedshooter   \n",
       "2         1430438400    5.0  34ffo5  cqug90z   InterimFatGuy   \n",
       "3         1430438401    1.0  34aqsn  cqug91c     JuanTutrego   \n",
       "4         1430438401  101.0  34f9rh  cqug91e     dcblackbelt   \n",
       "...              ...    ...     ...      ...             ...   \n",
       "4234965   1433116795    NaN  37y5rx  crrbelu      monster860   \n",
       "4234966   1433116795    NaN  37y5rx  crrbelv         jsimo36   \n",
       "4234967   1433116796    NaN  380jx2  crrbemp  torianicole731   \n",
       "4234968   1433116797    NaN  37yawp  crrbenh      bellypouch   \n",
       "4234969   1433116799    NaN  37zhvy  crrbeop   NotByAnyMeans   \n",
       "\n",
       "                                                      body parent_id     root  \\\n",
       "0        No one has a European accent either  because i...   cqug2sr  cqug2sr   \n",
       "1         That the kid ..reminds me of Kevin.   so sad :-(    34fvry   34fvry   \n",
       "2                                                     NSFL   cqu80zb  cqu80zb   \n",
       "3        I'm a guy and I had no idea this was a thing g...   cqtdj4m  cqtdj4m   \n",
       "4        Mid twenties male rocking skinny jeans/pants, ...   cquc4rc  cquc4rc   \n",
       "...                                                    ...       ...      ...   \n",
       "4234965  Does the sun set in the west/rise in the east?...    37y5rx   37y5rx   \n",
       "4234966                                           Coffee.     37y5rx   37y5rx   \n",
       "4234967  people who cannot make up their mind, my bulls...    380jx2   380jx2   \n",
       "4234968  Give them to Irish people in exchange for doin...    37yawp   37yawp   \n",
       "4234969                               classy way to put it   crragip   37zhvy   \n",
       "\n",
       "         depth  num_siblings  num_children  num_comments_author  \\\n",
       "0            1             1             0                    1   \n",
       "1            1          1443             0                    1   \n",
       "2            1             5             0                    1   \n",
       "3            1             4             0                    1   \n",
       "4            1             2             1                    1   \n",
       "...        ...           ...           ...                  ...   \n",
       "4234965      1          1496             0                    1   \n",
       "4234966      1          1496             0                    1   \n",
       "4234967      1             9             0                    1   \n",
       "4234968      1          1779             0                    1   \n",
       "4234969      7             1             0                    1   \n",
       "\n",
       "         num_previous_comments  num_later_comments  time_since_root  \\\n",
       "0                            0                   0         0.000000   \n",
       "1                            0                3512         0.000000   \n",
       "2                            0                  11         0.000000   \n",
       "3                            0                   4         0.000000   \n",
       "4                            0                   3         0.000000   \n",
       "...                        ...                 ...              ...   \n",
       "4234965                   3265                   0        12.452222   \n",
       "4234966                   3265                   0        12.452222   \n",
       "4234967                      8                   0         0.522500   \n",
       "4234968                   3519                   0        11.398056   \n",
       "4234969                    258                   0         5.230000   \n",
       "\n",
       "         time_since_parent  num_comments_subtree  height_subtree  \n",
       "0                 0.000000                     1               0  \n",
       "1                 0.000000                     1               0  \n",
       "2                 0.000000                     1               0  \n",
       "3                 0.000000                     1               0  \n",
       "4                 0.000000                     3               2  \n",
       "...                    ...                   ...             ...  \n",
       "4234965           0.000000                     1               0  \n",
       "4234966           0.000000                     1               0  \n",
       "4234967           0.000000                     1               0  \n",
       "4234968           0.000000                     1               0  \n",
       "4234969           0.501944                     1               0  \n",
       "\n",
       "[4234970 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keeping this jsut for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Toulouse School of Economics**\n",
    "#### **M2 Statistics & Econometrics**\n",
    "---\n",
    "## **Web Mining**\n",
    "### Final Project\n",
    "---\n",
    "#### Anh-Dung LE\n",
    "#### Sherman ALINE\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages and setting for multiprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, unidecode, re, os, json\n",
    "import matplotlib as plt\n",
    "import networkx as nx\n",
    "from networkx.algorithms.traversal.depth_first_search import dfs_tree\n",
    "#from dask.distributed import Client\n",
    "#import dask.dataframe as dd\n",
    "from nltk.corpus import stopwords\n",
    "from multiprocessing import dummy\n",
    "\n",
    "#core = os.cpu_count() - 2\n",
    "#client = Client(n_workers = core, threads_per_worker = 1, memory_limit = '25GB')\n",
    "my_stopwords = stopwords.words('english')\n",
    "#P = dummy.Pool(processes = core)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path('/Users/sma/Desktop/LEARNING/M2/S2/PROJ/webmin/comments_students.csv')\n",
    "df = pd.read_csv(path, header = 0, engine = 'c',\n",
    "                 usecols = ['created_utc', 'ups', 'link_id', 'id', 'author', 'body', 'parent_id'],\n",
    "                nrows = 10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>ups</th>\n",
       "      <th>link_id</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430438400</td>\n",
       "      <td>3.0</td>\n",
       "      <td>t3_34f9rh</td>\n",
       "      <td>cqug90j</td>\n",
       "      <td>jesse9o3</td>\n",
       "      <td>No one has a European accent either  because i...</td>\n",
       "      <td>t1_cqug2sr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1430438400</td>\n",
       "      <td>3.0</td>\n",
       "      <td>t3_34fvry</td>\n",
       "      <td>cqug90k</td>\n",
       "      <td>beltfedshooter</td>\n",
       "      <td>That the kid ..reminds me of Kevin.   so sad :-(</td>\n",
       "      <td>t3_34fvry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1430438400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>t3_34ffo5</td>\n",
       "      <td>cqug90z</td>\n",
       "      <td>InterimFatGuy</td>\n",
       "      <td>NSFL</td>\n",
       "      <td>t1_cqu80zb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1430438401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>t3_34aqsn</td>\n",
       "      <td>cqug91c</td>\n",
       "      <td>JuanTutrego</td>\n",
       "      <td>I'm a guy and I had no idea this was a thing g...</td>\n",
       "      <td>t1_cqtdj4m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1430438401</td>\n",
       "      <td>101.0</td>\n",
       "      <td>t3_34f9rh</td>\n",
       "      <td>cqug91e</td>\n",
       "      <td>dcblackbelt</td>\n",
       "      <td>Mid twenties male rocking skinny jeans/pants, ...</td>\n",
       "      <td>t1_cquc4rc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_utc    ups    link_id       id          author  \\\n",
       "0   1430438400    3.0  t3_34f9rh  cqug90j        jesse9o3   \n",
       "1   1430438400    3.0  t3_34fvry  cqug90k  beltfedshooter   \n",
       "2   1430438400    5.0  t3_34ffo5  cqug90z   InterimFatGuy   \n",
       "3   1430438401    1.0  t3_34aqsn  cqug91c     JuanTutrego   \n",
       "4   1430438401  101.0  t3_34f9rh  cqug91e     dcblackbelt   \n",
       "\n",
       "                                                body   parent_id  \n",
       "0  No one has a European accent either  because i...  t1_cqug2sr  \n",
       "1   That the kid ..reminds me of Kevin.   so sad :-(   t3_34fvry  \n",
       "2                                               NSFL  t1_cqu80zb  \n",
       "3  I'm a guy and I had no idea this was a thing g...  t1_cqtdj4m  \n",
       "4  Mid twenties male rocking skinny jeans/pants, ...  t1_cquc4rc  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove prefix so that columns `parent_id` and `link_id` have the same format as column `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parent_id'] = df['parent_id'].str.split('_', expand = True)[1]\n",
    "df['link_id'] = df['link_id'].str.split('_', expand = True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ind` is the indices of  \"normal\" rows that will be fed into the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = (df['body'] != 'deleted') & (df['body'] != '[deleted]') & df['body'].notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save this dataset for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS PART IS WHERE DUNGS CODES FOR GRAPHS ARE. DELETED FOR EASE OF DEVELOPMENT.\n",
    "#path = r'E:\\\\M2 EconStat\\\\Web Mining\\\\prefix_removed.csv'\n",
    "#df.to_csv(path, index = False, encoding =  'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summerize $10$ graph features we've extracted so far.\n",
    "\n",
    "- `depth`:\n",
    "\n",
    "- `num_siblings`:\n",
    "\n",
    "- `num_children`:\n",
    "\n",
    "- `num_comments_author`:\n",
    "\n",
    "- `num_previous_comments`:\n",
    "\n",
    "- `num_later_comments`:\n",
    "\n",
    "- `time_since_root`:\n",
    "\n",
    "- `time_since_parent`:\n",
    "\n",
    "- `num_comments_subtree`:\n",
    "\n",
    "- `height_subtree`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text featurization\n",
    "\n",
    "As a user of reddit I will apply some domain knowledge in the process of selecting text features. \n",
    "\n",
    "* text emotes - \n",
    "* emojis - emoticons may be used to detect sentiment. additionally they may signal a overly-casual post which may not be recieved well.\n",
    "\n",
    "* sentiment in post - funny comments, as well as serious and informative posts will get upvotes. in long comment threads, a hostile tone may get upvotes (for one party, while the other party with hostile tone will get many downvotes)\n",
    "    * (using TF-IDF) ?\n",
    "    * BERT ?\n",
    "\n",
    "* length - long comments may be an indication of high-information or high-effort post\n",
    "\n",
    "* #punctuation - this is another indicator that a post is likely to be well-written, correlated with useful information and understandable writing etc. all things which will get upvotes on AskReddit. Extremely large amounts of punctuation may also indicate visual text jokes being made using markdown.\n",
    "\n",
    "* #paragraphs - indicator of high amiount of content/contribution, high effort. \n",
    "               - we detect paragraphs by the numbe rof double spaces. doublespaces are removed on reddit, and thourhg manual investigation I have determined that double spaces in our corpora are new lines.\n",
    "\n",
    "* capital letters\n",
    "\n",
    "* number of links in a post - citations generally get upvotes, an indicator of sharing information.\n",
    "\n",
    "* sensitive content: contains 'NSFW' or 'NSFL'\n",
    "\n",
    "* refer to other users /u/*\n",
    "\n",
    "* refer to subreditt /r/\n",
    "\n",
    "* quotes\n",
    "\n",
    "markdown: https://daringfireball.net/projects/markdown/ https://www.reddit.com/r/reddit.com/comments/6ewgt/reddit_markdown_primer_or_how_do_you_do_all_that/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unparse html entities\n",
    "#-remove rows where body is NA.\n",
    "#- extract emojis, extract emoticons\n",
    "#- remove them ^^\n",
    "#- get number of links & remove them\n",
    "#- get length, number of punctuation, capital letters, num paragraphs (by finding \\n characters)\n",
    "#- run text cleaning\n",
    "#- sentiment analysis shit.\n",
    "\n",
    "# - &gt; is > which is used for quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HTMLParser\n",
    "# TODO &lt; &gt; probably others...\n",
    "\n",
    "# '   - ' bullet points (with a newline but that always works that way.)\n",
    "# '  ' new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_text = df.dropna(subset=['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Two things:  1) surely Word of God is very easy countered with Barthes' [Death of the Author](http://en.wikipedia.org/wiki/Death_of_the_Author) ?  2) I write for a living, I know what Word of God is. That's not what I'm talking about. I'm a gay woman, and if I was going to write a gay character they'd be gay. No need for me to say months after the book has sold millions of copies.  They'd just be gay. What JK is doing is trying to have her cake and eat it; she didn't write a gay character (or at least, she hinted so distantly at it that it wasn't possible to deduce without her say so) but she wants the *credit* for writing one and being progressive. So she says he's gay outside of the books canon and thus is completely meaningless to me and many other people. I understand that in fandom circles, it's fine for her to do that and in terms of x character crushes on y character it is. In terms of this, though, it's not. After she's sold millions of books to evangelicals, to homophobic nations, to homophobes and bigots she's turning around and saying oh this guys gay when she knows **a)** most of her audience will never find out she said that **b)** those that do and are offended by it can easily dismiss it because it's so poorly hinted at and quite frankly she could have made it up it makes so little difference**c)** most of those books have been sold already, she's losing a minority of sales. Do you see what I'm saying? This isn't an argument against or for Word of God, it's an argument that if she wanted to write a gay character she should have and not very very vaguely hint at it and then tell people months later, outside of the main canon. That's not LGBT representation, that's an author trying to have her cake and eat it.  \""
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_text.loc[df.body.str.contains('paragraphs', na=False)]\n",
    "df_text.loc[df_text.id=='crqm50x'].body[4145696]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#à² \n",
    "#i think paraghraphs arent retained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marko "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>I quit   What?!    <a href=\"https://www.youtube.com/watch?v=VYCehJk7UDE\">You have no idea, how high I can fly</a>    That scene popped up when you said &gt;and get repeatedly overlooked by corporate despite performing well...    Michael seems to get the shit end of stick even though he\\'s just a good guy, a bit of a goof, but still just a genuine good guy</p>\\n'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marko.convert(\"I quit   What?!    [You have no idea, how high I can fly](https://www.youtube.com/watch?v=VYCehJk7UDE)    That scene popped up when you said >and get repeatedly overlooked by corporate despite performing well...    Michael seems to get the shit end of stick even though he's just a good guy, a bit of a goof, but still just a genuine good guy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_prefix',\n",
       " 'children',\n",
       " 'inline_children',\n",
       " 'link_ref_defs',\n",
       " 'match',\n",
       " 'override',\n",
       " 'parse',\n",
       " 'parse_inline',\n",
       " 'priority',\n",
       " 'virtual']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(temp)\n",
    "#temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(temp.children)\n",
    "temp.override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#emoji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write text cleaning function which actually works.\n",
    "\n",
    "#def text_cleaning(df, colname, ind):\n",
    "#    \n",
    "#    tmp = df[colname][ind].copy()\n",
    "#    \n",
    "#    # Convert text to lowercase\n",
    "#    tmp = tmp.str.lower()\n",
    "#    \n",
    "#    # Delete punctuation\n",
    "#    tmp = tmp.str.replace('\\n', ' ')\n",
    "#    tmp = tmp.str.replace('\\r', ' ')    \n",
    "#    tmp = tmp.str.replace(r\"((?!{}).)\".format('(\\\\b[-/]\\\\b|[a-zA-Z0-9])'), ' ', regex = True)\n",
    "#    \n",
    "#    # Tokenize\n",
    "#    tmp = tmp.str.split()\n",
    "#    \n",
    "#    # Delete stop words\n",
    "#    tmp = tmp.apply(lambda x: [w for w in x if w not in my_stopwords])\n",
    "#    \n",
    "#    # Reverse tokenize\n",
    "#    df.loc[ind, colname] = tmp.map(lambda word: ' '.join(word))\n",
    "#    \n",
    "#\n",
    "#df2 = text_cleaning(df, 'body', ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fbb5c94d0786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ups'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "data = df['body']\n",
    "y = df['ups']\n",
    "\n",
    "n_feature = 50\n",
    "\n",
    "tfi_df_vec = TfidfVectorizer(use_idf = True,\n",
    "                             max_features = n_feature)\n",
    "\n",
    "X = tfi_df_vec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.33,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_jobs = -1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get the mean absolute error on the validation data\n",
    "y_pred = model.predict(X_test)\n",
    "MAE = mean_absolute_error(y_test , y_pred)\n",
    "print('Random forest validation MAE = ', MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBRegressor\n",
    "# XGBModel = XGBRegressor()\n",
    "# XGBModel.fit(X_train, y_train , verbose = False)\n",
    "\n",
    "# # Get the mean absolute error on the validation data :\n",
    "# XGBpredictions = XGBModel.predict(X_test)\n",
    "# MAE = mean_absolute_error(y_test , XGBpredictions)\n",
    "# print('XGBoost validation MAE = ', MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(1000, input_dim = 1000, activation = 'relu', kernel_initializer='normal'))\n",
    "# model.add(Dense(8, activation = 'relu', kernel_initializer='normal'))\n",
    "# model.add(Dense(1, activation = 'linear', kernel_initializer='normal'))\n",
    "# model.compile(loss = 'mean_absolute_error',\n",
    "#               optimizer = 'adam',\n",
    "#               metrics = ['accuracy'])\n",
    "# print(model.summary())\n",
    "# model.fit(X_train, y_train,\n",
    "#           epochs = 3,\n",
    "#           batch_size = 10,\n",
    "#           validation_data = (X_test, y_test),\n",
    "#           verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
